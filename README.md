# LLM & Agents pour la mobilit√© urbaine
*Rapport de projet*
> **Auteur :** Meriem DOGHECHE ‚Äì INFO FISA 5
> **Date :** 23 mai 2025
> **Remerciements :** Merci √† **Monsieur Adam** pour son encadrement et son aide tout au long de ce projet individuel.  Merci √† **Elena** pour ses retours sur le multimodal GTFS et l'API propos√© par gouvernement transport.data.gouv.fr.

---

## Table des mati√®res

0. [Guide de lancement rapide](#0-guide-de-lancement-rapide)
1. [Introduction](#1-introduction)
2. [Contexte et probl√©matique](#2-contexte-et-probl√©matique)
3. [√âtat de l‚Äôart](#3-√©tat-de-lart)
4. [Pr√©paration des donn√©es](#4-pr√©paration-des-donn√©es)  
   &nbsp;&nbsp;4.1 [Collecte et nettoyage](#41-collecte--nettoyage)  
   &nbsp;&nbsp;4.2 [√âquilibrage du corpus](#42-√©quilibrage-du-corpus)  
   &nbsp;&nbsp;4.3 [D√©coupage train / validation](#43-d√©coupage-entra√Ænement--validation)
5. [Comparaison des mod√®les de classification](#5-comparaison-des-mod√®les-de-classification)
6. [Pipeline de fine-tuning](#6-pipeline-de-fine-tuning)
7. [Architecture logicielle](#7-architecture-logicielle)  
   &nbsp;&nbsp;7.1 [Dispatcher](#71-dispatcher--dispatcherpy)  
   &nbsp;&nbsp;7.2 [Agent m√©t√©o](#72-agent-m√©t√©o--weather_agentpy)  
   &nbsp;&nbsp;7.3 [Agent transport](#73-agent-transports--transport_agentpy)  
   &nbsp;&nbsp;7.4 [Agents culture & loisirs](#74-agents-culture--loisirs--culture_agentpy-et-loisirs_agentpy)  
   &nbsp;&nbsp;7.5 [G√©olocalisation int√©gr√©e](#75-g√©olocalisation-int√©gr√©e)  
   &nbsp;&nbsp;7.6 [Interface Streamlit](#76-interface-utilisateur--streamlit-ui_apppy)
8. [Int√©gration des API ](#8-int√©gration-des-api)
9. [Planning & organisation](#9-planning--organisation)
10. [Points forts de la solution](#10-points-forts-de-la-solution)
11. [Limites et prochaines √©tapes](#11-limites-et-prochaines-√©tapes)
12. [Sitographie](#12-sitographie)


---
## 0. Guide de lancement rapide

| √âtape | Objectif | Commande | D√©tails                                                   |
|----:|-----------|----------|-----------------------------------------------------------|
| 1 | G√©n√©rer / MAJ le corpus | `cd training && python training_data_searching.py` | Scrape Reddit (1 200 posts) + nettoyage ‚Üí **train.jsonl** |
| 2 | Fine-tuner le dispatcher | `cd training && python finetune_dispatcher.py` | Produit **dispatcher_sbert.pt**                           |
| 3 | Lancer l‚Äôinterface | `streamlit run ui_app.py` | Chat local <http://localhost:8501> ; latence 1 s envisron |
| 4 | Tester | ¬´ Quel temps demain ? ¬ª / ¬´ Comment aller √† Gare de Lyon ? ¬ª | V√©rifier emoji ‚òÄÔ∏è / üöá et fra√Æcheur des donn√©es           |

> *Pr√©-requis :* `pip install -r requirements.txt` (20 librairies, il se peut qu'il ne soit pas √† jour car j'ai ajout√© au fur et √† mesure (potentiellement des installations inutiles)).  
> Variables n√©cessaires : `REDDIT_*`, `OPENAI_API_KEY`, `GOOGLE_MAPS_API_KEY`.  Je vous l'envoie par mail d√®s que possible.
> *Attention :* Les √©tapes 1 et 2 doivent √™tre lanc√©es **depuis le dossier `training/`**.

---

## 1. Introduction
Je constate au quotidien que pour organiser une simple sortie il me faut :
* ouvrir M√©t√©o-France pour v√©rifier la pluie,
* Citymapper pour l‚Äôitin√©raire,
* un blog culturel pour choisir une activit√©.

Cette dispersion nuit √† la spontan√©it√©.  
**Hypoth√®se :** un assistant conversationnel ¬´ tout-en-un ¬ª, tournant **localement**, peut supprimer ces frictions.

### Objectifs fix√©s
1. Un **dispatcher** qui achemine ‚â• 90 % des requ√™tes vers le bon agent (m√©t√©o, transport, culture, loisirs).
2. Quatre **agents sp√©cialis√©s** fonctionnant avec des donn√©es ouvertes et/ou gratuites.
3. Donn√©es √† jour
4. Utilisation de la g√©olocalisation 
---
## 2. Contexte et probl√©matique

### 2.1 Contexte

Je m‚Äôappelle **Meriem**, √©tudiante-ing√©nieure (INFO FISA 5) et utilisatrice quotidienne des transports en commun pour me rendre √† l‚Äôuniversit√© et organiser mes sorties :

- **M√©t√©o** : je v√©rifie M√©t√©o-France avant de partir, surtout en ce moment o√π, dans la m√™me journ√©e, il peut faire 3¬∞C le matin et 20 l'apr√®s-midi.
- **Trajets** : j‚Äôouvre Citymapper ET la page SNCF pour les horaires.
- **Id√©es de sorties** : je cherche sur des blogs ou les r√©seaux sociaux.

Ces informations sont **s√©par√©es** et n√©cessitent plusieurs applications ou onglets.  
Dans le m√™me temps, l‚Äô√âtat fran√ßais publie de plus en plus de **donn√©es ouvertes** (transport.data.gouv.fr, Open-Meteo, agendas culturels), mais aucune application locale ne les r√©unit simplement.

### 2.2 Probl√©matique

Cr√©er un **assistant conversationnel local** qui :

| D√©fi | Description                                                                                                                               | Impact attendu |
|------|-------------------------------------------------------------------------------------------------------------------------------------------|----------------|
| 1. **Compr√©hension** | Interpr√©ter des questions vari√©es, parfois ambigu√´s ou bilingues (FR/EN).                                                                 | R√©ponses naturelles sans formalisme technique. |
| 2. **Fusion de donn√©es** | Regrouper : <br>‚Ä¢ m√©t√©o (Open-Meteo)  <br>‚Ä¢ horaires des transports (transport.data.gouv.fr ou autre)  <br>‚Ä¢ √©v√©nements culturels/loisirs | Vue ‚Äútout-en-un‚Äù pour l‚Äôutilisateur. |
| 3. **R√©activit√© locale** | Fonctionner hors-ligne ou avec r√©seau limit√©, gr√¢ce √† un cache et √† un mod√®le embarqu√©.                                                   | Temps de r√©ponse < 2 s sur PC portable. |
| 4. **Co√ªt z√©ro & open-source** | S‚Äôappuyer sur des API gratuites et des mod√®les d√©ployables sur CPU.                                                                       | Accessible √† tout √©tudiant sans budget cloud. |

En r√©sum√©, l‚Äôobjectif est de **r√©unir m√©t√©o, trajets et id√©es de sortie dans une seule discussion** ‚Äî sans d√©pendre d‚Äôun serveur externe co√ªteux ‚Äî afin de fluidifier la vie quotidienne d‚Äôun¬∑e √©tudiant¬∑e ou d‚Äôun¬∑e citadin¬∑e.

---

## 3. √âtat de l‚Äôart
| Cat√©gorie | Solution | Avantages | Limites pour ce projet                                  |
|-----------|----------|-----------|---------------------------------------------------------|
| Assistants vocaux | Google Assistant, Siri | Interface vocale, √©cosyst√®me solide | Cloud-first, prompts longs, co√ªt API, temps insuffisant |
| Apps mobilit√© | Citymapper, Transit | Multimodal pr√©cis | Pas de contexte m√©t√©o/culture                           |
| Frameworks d‚Äôagents | **LangChain Agents** (2023) | Orchestration Python-friendly | D√©pend GPT-3.5 / OpenAI                                 |
| Orchestration avanc√©e | **Microsoft AutoGen** (2024) | Collaboration multi-LLM | Azure obligatoire, tokens on√©reux                       |
| Recherche acad√©mique | Router-LLM (ACL 2024) | F1 0.88 router | N√©cessite GPU A100 80 Go, mon PC ne suit pas            |

**D√©cision :** repartir de z√©ro pour ma√Ætriser la pile **local-first** et respecter le budget √©tudiant (0 ‚Ç¨).

---

## 4. M√©thodologie globale

## 4. Pr√©paration des donn√©es

### 4.1 Collecte & nettoyage

| √âtape                     | Outil / Script                 | Dur√©e    | R√©sultat                                                   |
|---------------------------|--------------------------------|----------|------------------------------------------------------------|
| Scraper Reddit            | `DataFetcher` (lib PRAW)       | 3 jours  | Jusqu‚Äô√† 1 000 questions par cat√©gorie (transport, m√©t√©o...) |
| Nettoyage                 | Regex, `unidecode`             | ¬Ω jour   | Suppression des doublons, accents, sauts de ligne          |
| Annotation automatique    | `DataFetcher._PATTERNS`        | instantan√© | Attribution de 4 labels via des expressions r√©guli√®res     |
| Ajout de questions cibl√©es| `questions_meteo.jsonl`, `questions_loisir.jsonl` | ¬Ω jour | Plus de diversit√© pour les classes sous-repr√©sent√©es       |
| Relecture manuelle        | LibreOffice + Antidote         | 1 jour   | Environ 800 phrases revues et corrig√©es                    |

> **Pourquoi Reddit ?**
> - Des donn√©es r√©elles et vari√©es, √©crites par des humains
> - Facilit√© d‚Äôacc√®s via API d√©veloppeur
> - Moins de bruit que des donn√©es g√©n√©r√©es artificiellement
> - Subreddits en 403 ou vides sont ignor√©s automatiquement

---

### 4.2 √âquilibrage du corpus

Le script `DataFetcher.run()` applique un √©quilibrage simple :  
chaque cat√©gorie re√ßoit au maximum 1 000 exemples. Si une classe contient moins de 2 exemples, des duplications sont appliqu√©es.

| Classe     | Ex. Reddit | + Questions extra | Total approx.                     |
|------------|------------|-------------------|-----------------------------------|
| Transport  | 20         | ‚Äî                 | 20 (le mod√®le originel suffisait) |
| M√©t√©o      | 1          | +40               | 41                                |
| Culture    | 200        | ‚Äî                 | 200                               |
| Loisirs    | 800        | +200              | 1000                              |

**Total estim√©** : **‚âà 1500** questions francophones.

---

### 4.3 D√©coupage entra√Ænement / validation

- Les donn√©es sont m√©lang√©es al√©atoirement avec `random.shuffle()`
- R√©partition classique 80 / 20 :
    - **train.jsonl** pour l‚Äôentra√Ænement
    - **val.jsonl** pour la validation

> Aucun passage par Google Translate :  
> Le corpus final est **100 % francophone**.  
> La traduction automatique a √©t√© test√©e mais abandonn√©e (trop bruyante, peu utile + passage par une autre API).


---

## 5. Comparaison des mod√®les de classification

Avant de choisir un mod√®le, j‚Äôai compar√© plusieurs ¬´ grosses briques ¬ª pr√©-entra√Æn√©es.  
Chaque brique peut √™tre adapt√©e (fine-tuning) √† nos quatre cat√©gories.  
Tout est disponible gratuitement sur la plateforme **Hugging Face**.

> **MPNet** est un mod√®le publi√© par Microsoft.  
> Sa version de base est d√©crite ici :  
> <https://huggingface.co/microsoft/mpnet-base/discussions>  
> J‚Äôai retenu la variante **`sentence-transformers/paraphrase-multilingual-mpnet-base-v2`**  
> car elle sait d√©j√† g√©rer plusieurs langues, dont le fran√ßais, et produit directement
> des vecteurs de phrases faciles √† r√©utiliser.


| Mod√®le | Params | Langues | F1-macro (XNLI) | VRAM T4 | Latence CPU i7 | Verdict |
|--------|-------:|--------:|----------------:|--------:|---------------:|---------|
| **MPNet-base-v2** | 278 M | 100+ | **0.83** | 1 Go | 110 ms | **Choisi** |
| DistilBERT-m-cased | 134 M | 104 | 0.78 | 650 Mo | 85 ms | l√©ger mais ‚Äì5 pp F1 |
| CamemBERT-base | 110 M | üá´üá∑ | 0.80 | 580 Mo | 90 ms | FR-native, pas multilingue |
| LaBSE | 471 M | 109 | 0.85 | 2 Go | 180 ms | Trop lourd |
| MiniLM-L12-v2 | 118 M | 110 | 0.78 | 450 Mo | **55 ms** | ultra-rapide, vecteur 384 D |

### Que signifient les colonnes ?

* **Params** ‚Äì nombre de param√®tres (taille du mod√®le, plus c‚Äôest grand, plus c‚Äôest lourd). Avec mon PC, je ne pouvais malheureusement de choisir quelque chose de lourd.
* **Langues** ‚Äì combien de langues le mod√®le comprend ‚Äú√† peu pr√®s‚Äù.
* **F1-macro (XNLI)** ‚Äì score moyen sur un benchmark multilingue ; plus il est haut, mieux le mod√®le raisonne.
* **VRAM T4** ‚Äì m√©moire GPU n√©cessaire pour l‚Äôutiliser (carte Nvidia T4).
* **Latence CPU i7** ‚Äì temps moyen (en millisecondes) pour traiter une phrase sur un PC portable.
* **Verdict** ‚Äì r√©sum√© rapide de mes tests/contraintes.


### Pourquoi j‚Äôai pris MPNet (multilingual)

* **Assez l√©ger** : il occupe moins de 1 Go de m√©moire vid√©o, donc il tourne sur un PC normal.
* **Comprend plus de 100 langues** : le fran√ßais bien s√ªr, mais aussi l‚Äôanglais si la question m√©lange les deux.
* **Pr√™t √† l‚Äôemploi** : la version ‚Äúsentence-transformers‚Äù donne directement un vecteur pour chaque phrase ; je n‚Äôai presque rien √† ajouter pour classer mes questions.

En pratique, le mod√®le **`paraphrase-multilingual-mpnet-base-v2`** tourne sans probl√®me sur mon CPU, tout en restant assez pr√©cis pour classer correctement m√©t√©o, transport, culture et loisirs.

---
## 6. Pipeline de fine-tuning

### 6.1 `training_data_searching.py`

Ce script sert √† **fabriquer le jeu de donn√©es** :

1. **R√©cup√©ration sur Reddit**
    - M√©thode `fetch_label()`
        - Cherche des titres de posts contenant des mots-cl√©s pr√©cis, par th√®me :
            - transport, m√©t√©o, culture, loisirs.
        - Ignore :
            - Les subreddits priv√©s (erreur 403).
            - Les titres d√©j√† vus, trop courts ou sans point d‚Äôinterrogation.
        - Limite : `max_per_label = 1000` questions par th√®me.

2. **Nettoyage**
    - Fonction `clean()`
        - Supprime les sauts de ligne, espaces multiples et accents bizarres.

3. **√âtiquetage automatique**
    - Gr√¢ce aux expressions r√©guli√®res d√©finies dans `PATTERNS`, chaque titre re√ßoit l‚Äôun des 4 labels.

4. **Compl√©ments hors-Reddit**
    - Fichiers `questions_meteo.jsonl` et `questions_loisir.jsonl` ajout√©s pour √©quilibrer les classes m√©t√©o et loisirs.

5. **√âquilibrage minimum**
    - Si une classe poss√®de < 2 exemples, le script duplique une ou deux phrases pour √©viter les erreurs de split.

6. **M√©lange puis d√©coupe 80 / 20**
    - 80 % ‚Üí **train.jsonl**
    - 20 % ‚Üí **val.jsonl**

Comme explicit√© pr√©c√©demment, j‚Äôai choisi Reddit parce qu‚Äôil offre beaucoup de donn√©es r√©elles et vari√©es. Une autre option aurait √©t√© d'utiliser des donn√©es synth√©tiques g√©n√©r√©es par un mod√®le comme GPT, mais cela aurait pu introduire des phrases moins naturelles et r√©duire la qualit√© de l‚Äôapprentissage.
Reddit est utile car il y'a un mode d√©veloppeur sur lequel j'ai cr√©√© un script pour r√©cup√©rer les jeux de donn√©es.

Appuyer sur **create an app** : 
![reddit.png](assets/reddit.png)

Choisir **script** + emplir les champs suivants
![reddit_creation_script.png](assets/reddit_creation_script.png)


### 6.2 `finetune_dispatcher.py`

Le fine-tuning veut dire adapter un mod√®le d√©j√† entra√Æn√© pour qu'il comprenne mieux les questions sp√©cifiques √† mon projet. 
Dans ce cas, j'ai utilis√© le mod√®le SBERT MPNet, car il est performant, multilingue, donc utilisable pour le fran√ßais, et suffisamment l√©ger pour fonctionner sur mon ordinateur personnel.
Bien que pratique, certaines phrases tels que "Quel temps fait-il ?" n'√©taient pas bien classfi√©es. Apr√®s discussion avec Monsieur Adam, je suis partie sur du fine-tuning.

Voici comment j'ai proc√©d√© en d√©tails :

* **Pr√©paration des donn√©es :** J‚Äôai charg√© mes donn√©es d√©j√† class√©es en quatre cat√©gories : transport, m√©t√©o, culture et loisirs.

* **Pourquoi ¬´ d√©geler ¬ª certaines couches ?**

    * Le mod√®le SBERT est initialement entra√Æn√© sur des donn√©es tr√®s g√©n√©rales. Pour le sp√©cialiser, il faut modifier ses derni√®res couches (les plus proches de la sortie). J‚Äôai d√©cid√© de ¬´ d√©geler ¬ª les 4 derni√®res couches car elles capturent mieux les nuances sp√©cifiques de mes questions.

* **Pourquoi ces param√®tres ?**

    * **Batch size (32)** : Pour trouver un √©quilibre entre rapidit√© et stabilit√© de l'entra√Ænement.
    * **Epochs (8)** : Suffisantes pour que le mod√®le apprenne bien sans commencer √† m√©moriser par c≈ìur.
    * **Learning rate** :

        * **LR\_HEAD (2e-4)** : Taux d‚Äôapprentissage √©lev√© pour que la t√™te de classification s‚Äôadapte vite.
        * **LR\_BERT (2e-5)** : Plus bas pour ajuster doucement les couches SBERT d√©j√† entra√Æn√©es sans les perturber.
    * **Dropout (0.3)** : √âvite que le mod√®le m√©morise trop pr√©cis√©ment les donn√©es, assurant ainsi une bonne g√©n√©ralisation.

* **Pourquoi ces valeurs ?**

    * Ces valeurs sont couramment utilis√©es en pratique mais j‚Äôai aussi fait plusieurs tests pour ajuster ces valeurs et trouver les meilleures performances possibles pour mon projet. Je suis notamment tomb√©e sur des situations tel que le sur-apprentisage.

### 6.3 Fichiers produits

* **`dispatcher_sbert.pt`** : fichier final qui contient les poids entra√Æn√©s de SBERT et la t√™te de classification.
* **`clf.pkl`** : fichier contenant une r√©gression logistique, utilis√© comme r√©f√©rence (baseline) pour comparer les performances avec le mod√®le SBERT.

---

## 7. Architecture logicielle

L'architecture logicielle de mon projet s'articule autour d'une structure modulaire bas√©e sur un dispatcher central et plusieurs agents sp√©cialis√©s (m√©t√©o, transports, culture, loisirs). Chaque agent a un r√¥le clair et ind√©pendant, facilitant ainsi les futures √©volutions.

### 7.1 Dispatcher ‚Äì `dispatcher.py`

Le dispatcher est le c≈ìur d√©cisionnel du syst√®me. Son r√¥le est de comprendre la question de l'utilisateur et de l'envoyer au bon agent (transport, m√©t√©o, culture ou loisirs).

Pour cela, le dispatcher utilise SBERT (Sentence-BERT). SBERT est un mod√®le qui comprend le sens g√©n√©ral d‚Äôune phrase en la transformant en chiffres appel√©s ¬´vecteurs¬ª. Une fois la phrase transform√©e, une petite partie du mod√®le (appel√©e ¬´t√™te de classification¬ª) utilise ces chiffres pour choisir la bonne cat√©gorie.

Si la cat√©gorie choisie n'est pas assez s√ªre, le dispatcher cherche des mots simples dans la phrase (comme ¬´ m√©t√©o ¬ª ou ¬´ bus ¬ª) pour mieux d√©cider. Finalement, il transmet la question √† l‚Äôagent adapt√©, qui r√©pond clairement √† l'utilisateur.
#### Librairies et technologie utilis√©es :

* **Sentence-Transformers** : mod√®le SBERT multilingue pour encoder les requ√™tes.
* **PyTorch** : d√©j√† utilis√© en cours, cr√©ation de la t√™te de classification (couches lin√©aires et dropout).
* **regex** : fallback via expressions r√©guli√®res pour g√©rer les cas incertains.
* **logging** : suivi pr√©cis des requ√™tes et erreurs.

#### Explication technique :

* **Chargement du mod√®le fine-tun√©** : Le mod√®le SBERT (`paraphrase-multilingual-mpnet-base-v2`) est charg√© √† partir d'un checkpoint PyTorch (`dispatcher_sbert.pt`) que j'ai entra√Æn√© pr√©c√©demment.
* **Classification des requ√™tes** : Une t√™te de classification compos√©e de deux couches lin√©aires avec activation ReLU et dropout permet d'obtenir un score pour chacune des cat√©gories.
* **Gestion des seuils** :

 * Si le score maximal obtenu est sup√©rieur √† `0.50`, la cat√©gorie principale est s√©lectionn√©e.
 * Entre `0.35` et `0.50`, le dispatcher v√©rifie via regex les mots-cl√©s pour s'assurer de la pertinence.
 * En dessous de `0.35`, seul le fallback par regex est utilis√©.
* **Cache LRU (Least Recently Used)** : Optimise les performances en m√©morisant les embeddings des requ√™tes r√©centes (jusqu'√† 256 requ√™tes).


---
### üìà R√©sultats du fine-tuning

#### Courbes de perte par epochs
![Figure_1.png](assets/Figure_1.png)

#### Scores de validation par epochs
![Figure_2.png](assets/Figure_2.png)

### ‚úÖ Pourquoi c‚Äôest un bon r√©sultat ?

#### üìâ Perte qui baisse
- La perte d‚Äôentra√Ænement et de validation chute r√©guli√®rement (de 1,3 √† environ 0,6).
- Aucune remont√©e brutale : le mod√®le apprend de mieux en mieux sans se tromper.

#### ‚öñÔ∏è √âcart ma√Ætris√©
- La courbe de perte validation reste en dessous de celle de l‚Äôentra√Ænement.
- Cela montre que le mod√®le **g√©n√©ralise bien** : il n‚Äôapprend pas par c≈ìur les donn√©es.

#### üéØ Balanced accuracy ‚âà 0,97
- Cet indicateur tient compte du **d√©s√©quilibre entre classes**.
- Un score de 0,97 signifie que le mod√®le pr√©dit correctement **chaque cat√©gorie**, m√™me les moins repr√©sent√©es.

#### ‚úÖ Accuracy brute ‚âà 0,94
- M√™me sans tenir compte des d√©s√©quilibres, le mod√®le atteint **94 % de bonnes r√©ponses**.
- Il ne se contente pas de deviner la classe la plus fr√©quente.

---

Ces courbes montrent un apprentissage **progressif, stable et efficace**.  
Le mod√®le est **tr√®s pr√©cis** et sait r√©pondre correctement **√† tous les types de requ√™tes**.

---

### 7.2 Agent m√©t√©o ‚Äì `weather_agent.py`

#### API et librairies utilis√©es :

* **Open-Meteo** : API m√©t√©o gratuite, sans cl√© d'API.
* **requests** : appels HTTP.
* **regex & dateparser** : extraction des villes et dates du texte.

#### D√©tails des fonctions :

* `extract_city()` : extrait la ville mentionn√©e apr√®s les pr√©positions ¬´ √† ¬ª ou ¬´ pour ¬ª.
* `get_coordinates()` : r√©cup√®re les coordonn√©es g√©ographiques via l'API de g√©ocodage Open-Meteo.
* `map_weather_code()` : traduit les codes m√©t√©o en texte fran√ßais clair.
* `handle_request()` : int√®gre les trois fonctions pr√©c√©dentes pour retourner un r√©sum√© m√©t√©o complet et simple √† comprendre par l'utilisateur.

L'avantage majeur de l'API Open-Meteo est son acc√®s gratuit et ses donn√©es mises √† jour chaque heure, rendant le service r√©actif et pertinent pour les utilisateurs.

---

### 7.3 Agent transports ‚Äì `transport_agent.py`

#### API et librairies utilis√©es :

* **Google Maps Directions API** : itin√©raires d√©taill√©s et multimodaux.
* **OpenAI GPT-4o-mini** : reformulation des requ√™tes en cas d'ambigu√Øt√©.
* **regex** : extraction basique ¬´ de X √† Y ¬ª.
* **datetime** : gestion temporelle des itin√©raires.


#### D√©tails des fonctions :

* `classify_request()` : classifie la requ√™te en itin√©raire (`ITINERARY`) ou question g√©n√©rale (`GENERAL`) gr√¢ce √† GPT-4o-mini.
* `extract_parameters()` : extrait les origines et destinations en priorit√© par regex, puis en fallback avec NER via SpaCy.
* `reformulate()` : reformulation par GPT-4o-mini des phrases ambigu√´s en forme standard "de X √† Y".
* `handle_request()` : combine les fonctions pr√©c√©dentes, interroge Google Maps Directions, et formate une r√©ponse claire et d√©taill√©e en markdown.

Le choix de Google Maps Directions API s'impose par sa fiabilit√©, son exhaustivit√© et ses donn√©es √† jour, m√™me si l'int√©gration OpenTripPlanner reste une possibilit√© future pour une gestion locale compl√®te.

---

### 7.4 Agents culture & loisirs ‚Äì `culture_agent.py` et `loisirs_agent.py`

Ces deux agents utilisent GPT-4o afin d'exploiter la puissance des mod√®les LLM dans des contextes tr√®s ouverts et moins structur√©s que la m√©t√©o ou les transports.

#### Agent Culture :

* **GPT-4o** : g√©n√®re des anecdotes historiques et culturelles riches et pr√©cises.
* Prompt sp√©cialis√© pour maximiser la pertinence dans le contexte du patrimoine et de l'histoire locale.
* Conversation suivie avec contexte (historique de la conversation).

#### Agent Loisirs :

* **GPT-4o** : recommandations personnalis√©es d'activit√©s et d'√©v√©nements en temps r√©el.
* Historique de conversation permettant de contextualiser la requ√™te (suivi des interactions utilisateur-agent).

Le choix de GPT-4o pour ces deux agents d√©coule de la difficult√© d'avoir des bases de donn√©es locales exhaustives et √† jour dans ces domaines, et de l'excellence reconnue de GPT-4o pour des t√¢ches de g√©n√©ration textuelle libre et de r√©ponse contextuelle.

---

### 7.5 G√©olocalisation int√©gr√©e

La g√©olocalisation est trait√©e dans l'agent m√©t√©o et transport :

* Dans l'agent m√©t√©o, l'API de g√©ocodage Open-Meteo permet de convertir automatiquement des noms de villes en coordonn√©es pr√©cises.
* Dans l'agent transport, Google Maps Directions g√®re nativement la g√©olocalisation et la reconnaissance automatique des noms de lieux complexes (stations, gares, lieux publics).

Ce double syst√®me assure une couverture compl√®te et fiable des besoins de g√©olocalisation.
Attention, la g√©olocalisation ne sera utilis√©e que si l'utilisateur donne l'autorisation explicite au niveau du front.

---

### 7.6 Interface utilisateur ‚Äì Streamlit (`ui_app.py`)

L'interface utilisateur est d√©velopp√©e avec **Streamlit**, un framework Python l√©ger et rapide pour cr√©er des interfaces web interactives.

#### Avantages de Streamlit :

* Rapidit√© de d√©veloppement (quelques heures pour un prototype fonctionnel).
* Markdown int√©gr√© pour des r√©ponses structur√©es et agr√©ables visuellement.
* Facilit√© d'utilisation sans comp√©tences web avanc√©es.

#### Limites actuelles :

* Pas de gestion automatique du scroll dans les conversations.
* Pas de support natif pour les interactions vocales ou multim√©dia avanc√©es.

#### Alternatives envisag√©es :

* **Gradio** : rapide mais moins ergonomique que Streamlit.
* **Dash** : puissant mais complexe pour un usage rapide.
* **React + FastAPI** : tr√®s robuste mais demande davantage de ressources en temps, chose que je n'avais pas.

Le choix de Streamlit r√©pond parfaitement aux contraintes temporelles et budg√©taires actuelles, tout en assurant une exp√©rience utilisateur satisfaisante pour un prototype fonctionnel.

---

### Conclusion sur l'architecture :

L'architecture retenue est robuste, modulaire, et facilement extensible gr√¢ce √† une s√©paration claire des pr√©occupations (dispatcher vs agents m√©tiers vs interface utilisateur). Les choix technologiques (SBERT, GPT-4o, Streamlit, Open-Meteo, Google Maps API) r√©pondent pr√©cis√©ment aux contraintes initiales d'un projet √©tudiant (co√ªt z√©ro, rapidit√© d'ex√©cution, facilit√© d'√©volution).

Les pistes futures (multi-intent, gestion vocale, OpenTripPlanner local) ont d√©j√† √©t√© identifi√©es et pourront s'int√©grer facilement dans cette structure modulaire et clairement d√©finie.

---

## 8. Int√©gration des API

| Service (lien) | Cl√© API ? | Quota gratuit | √Ä quoi √ßa sert ? | D√©cision |
|----------------|-----------|--------------|------------------|----------|
| [Open-Meteo](https://open-meteo.com/) | non | illimit√© | Pr√©visions et m√©t√©o actuelle | ‚úÖ |
| [Google Maps Directions](https://developers.google.com/maps/documentation/directions) | oui | **2 mois gratuits**| Itin√©raires bus / train / m√©tro | ‚úÖ |
| [OpenAI Chat (GPT-4o)](https://platform.openai.com/) | oui | **11 USD de cr√©dits** prolong√©s jusqu‚Äôau **30 avril 2025** | R√©ponses culture & loisirs + reformulation transport | ‚úÖ |
| Reddit API | oui | 60 req/min | Collecte initiale des questions | ‚òëÔ∏è (termin√©) |
| OpenTripPlanner (self-host) | non | ‚Äî  | Itin√©raires hors-ligne | üîú (√† venir) |


---

## 9. Planning & organisation

| Sprint (2 sem.) | Dates 2025        | T√¢che principale                             | Livrable                                |
|-----------------|-------------------|----------------------------------------------|-----------------------------------------|
| **S1‚ÄìS2**       | 05 ‚Üí 18 f√©vr.     | Cadrage du besoin, cr√©ation du backlog       | To Do list                              |
| **S3‚ÄìS4**       | 19 f√©v. ‚Üí 03 mars | Scraper Reddit + nettoyage                   | `raw_posts.json`                        |
| **S5‚ÄìS6**       | 04 ‚Üí 17 mars      | Fine-tuning du classifieur SBERT (compliqu√©) | `dispatcher_sbert.pt`                   |
| **S7‚ÄìS8**       | 18 ‚Üí 31 mars      | D√©veloppement de l‚Äôagent m√©t√©o + dispatcher | `weather_agent.py`                      |
| **S9‚ÄìS10**      | 01 ‚Üí 14 avr.      | Agent transport (Google Maps + GPT)          | `transport_agent.py`                    |
| **S11**         | 15 ‚Üí 28 avr.      | Agents culture & loisirs                     | `culture_agent.py`, `loisirs_agent.py`  |
| **S12**         | 29 avr. ‚Üí 12 mai  | Interface Streamlit + tests                  | `ui_app.py`                             |
| **S13**         | 13 ‚Üí 19 mai       | R√©daction finale & visuels                   | README, graphiques                      |

> **Difficult√©s majeures** : r√©gler le seuil de la classification SBERT et extraire proprement ¬´ de X √† Y ¬ª dans l‚Äôagent transport.

---

## 10. Points forts de la solution

* **Mode local** : tout fonctionne sur un PC sans serveur externe, sauf les appels OpenAI et Google Maps.
* **Structure modulable** : chaque nouvel agent (ex. ‚Äúgastronomie‚Äù) se cr√©e en ¬± 90 lignes.
* **Donn√©es fran√ßaises r√©elles** : corpus Reddit relu √† la main, meilleure pertinence FR.

---

## 11. Limites et prochaines √©tapes

### Limites actuelles
* Une seule intention √† la fois : impossible de demander ¬´ m√©t√©o **et** trajet ¬ª en une phrase.
* L‚Äôagent transport d√©pend encore de GPT-4o pour reformuler certaines questions.
* Interface Streamlit tr√®s simple : pas de d√©filement auto au niveau de la discussion, pas de commande vocale.

### Feuille de route simplifi√©e
1. **Classer plusieurs intentions en m√™me temps** : permettre ¬´ Quel temps et quel train pour Maubeuge ? ¬ª.
2. **R√©duire la taille du mod√®le** : passer en format l√©ger (ONNX int8) pour tourner sur Android.
3. **Ajouter la voix** : utiliser un petit outil (Whisper-cpp) pour parler et √©couter l‚Äôutilisateur.
4. **Itin√©raires hors-ligne** : emballer OpenTripPlanner dans un conteneur Docker pour l‚Äôutiliser sans Internet.

---

## 12. Sitographie

| Th√®me | Ressource | Lien |
|-------|-----------|------------|
| **Classification de phrases** | Guide scikit-learn ‚ÄúWorking with text data‚Äù | <https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html> |
|  | Documentation Sentence-Transformers (SBERT) | <https://www.sbert.net/docs/quickstart.html> |
| **Mod√®les pr√©-entra√Æn√©s** | MPNet base (Microsoft) | <https://huggingface.co/microsoft/mpnet-base> |
|  | Variante multilingue utilis√©e | <https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2> |
| **API m√©t√©o** | Open-Meteo ‚Äì documentation | <https://open-meteo.com/en/docs> |
| **API transport** | Google Maps Directions ‚Äì overview | <https://developers.google.com/maps/documentation/directions/overview> |
|  | GTFS France (transport.data.gouv.fr) | <https://transport.data.gouv.fr/datasets> |
| **API culture / loisirs** | Liste des mus√©es de France (open data) | <https://data.culture.gouv.fr/> |
| **Open source mobilit√©** | Projet OpenTripPlanner | <https://www.opentripplanner.org/> |
| **Framework UI** | Documentation Streamlit | <https://docs.streamlit.io/> |
| **Cr√©dits OpenAI gratuits** | Annonce prolongation des tokens | <https://community.openai.com/t/free-tokens-on-traffic-shared-with-openai-extended-through-april-30-2025/1129643> |
